exp_name: right-VUNnet
log_dir: ./log
ckpt_dir: ./ckpt

losses:
    color_L1:
        weight: 0.
    color_gradient:
        weight: 0.5
    KL:
        start_ramp_it: 500
        end_ramp_it: 60000  #  200K in total
        start_ramp_val: 0.01
        end_ramp_val: 1
    perceptual:
        weight: 5
        vgg_feat_weights: [1,1,1,1,1,1]
        gram_feat_weigths: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
#    gram:
#        gram_weights: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
# Mandatory Training Parameters
batch_size: 4
num_epochs: 40

# Learning rate
lr: 0.0001

model_pars:
    # Activation after final decoding layer
    final_act: False
    # Feature depth after first encoding convolution.
    # Will be doubled after each stage
    nf_start: 64
    # Maximum depth of features during encoding and decoding
    nf_max: 128
    # Height and width of the input images. These must always be quadratic
    spatial_size: 256
    # Dropout probability
    dropout_prob: 0.1
    # Number of channels of the appearance input (3 for RGB, 4 for RGBA)
    # This defines also the number of output channels.
    img_channels: 3
    # Number of channels for the pose input. This implementation uses RGB
    # stickmen, but it is not uncommon to also use heatmaps with a channel per
    # keypoint of the pose descriptor.
    pose_channels: 3

    # in-plane factor
    in_plane_factor: 2
    # num of crops
    num_crops: 8