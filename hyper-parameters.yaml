losses:
    l1:
        weight: 0.5
    KL:
        start_ramp_it: 2000
        end_ramp_it: 3500
        start_ramp_val: 0
        end_ramp_val: 1
    vgg:
        weight: 1.
        vgg_feat_weights: [1,1,1,1,1,1]
    gram:
        gram_weights: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
# Mandatory Training Parameters
batch_size: 4
num_epochs: 20

# Learning rate
lr: 0.00003

model_pars:
    # Activation after final decoding layer
    final_act: True
    # Feature depth after first encoding convolution.
    # Will be doubled after each stage
    nf_start: 64
    # Maximum depth of features during encoding and decoding
    nf_max: 128
    # Height and width of the input images. These must always be quadratic
    spatial_size: 256
    # Dropout probability
    dropout_prob: 0.0
    # Number of channels of the appearance input (3 for RGB, 4 for RGBA)
    # This defines also the number of output channels.
    img_channels: 3
    # Number of channels for the pose input. This implementation uses RGB
    # stickmen, but it is not uncommon to also use heatmaps with a channel per
    # keypoint of the pose descriptor.
    pose_channels: 3

    # in-plane factor
    in_plane_factor: 2